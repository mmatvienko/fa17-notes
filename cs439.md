# CS 439H
## Gheith's spinLock
```c++
class SpinLock{
    Atomic<bool> isTaken = false;
public:
    lock(){
        while(isTaken.exchange(true));
        // exchange returns value at location
    }
    unlock(){
        isTaken.set(false);
    }
}
```
If ```isTaken``` is true to start with you will just an infinite loop. If initially false, and is changed to true and that is returned, we know we are allowed to go and do work.

## Semaphore
```c++
class Semaphore {
    uint32_t count;
    Queue<Thread> blocked
public:
    Semaphore (uint32_t count) : count(count), blocked(new Queue<Thread>());
    void down(){
        if (count == 0){
            blocked.add(Thread::current);
            Thread::yield(); // don't add self to readyQ
        }else{
            count--; // being atomic would not help much
        }
    }
    void up(){}
}
```
You cannot surround ```down()``` with a lock i.e.
```c++
lock.lock(){

}lock.unlock
```
System would spin, and there would be no way to unlock the lock. Semaphore would be done with.
Must build mechanism to release the Semaphore


```c++
//down:
lock();
if(count == 0){
    blocked.add(me);
    unlock();
}
```
Thread A is running the former. Around the same time Thread B (runs the latter) gets spinlock and tries to help Thread A onto the readyQ
```c++
//up:
lock();
if(someoneIsWaiting){
    readyQ->add(someone);
}
```
* What if someone changes ```count``` while a thread is trying to block.
    * Run yield before unlock, and only unlock if yield is successful 
    * Add a new **DND** state that tells other threads not to bother you. Allowing you to finish your job


Create idleThread for cores to run when they have nothing to do.
```c++
if(first){
    //  .
    //  .
    //  .
    kernelMain();
}else{
    while(true)Thread::yield();
}
```
```currentThread``` using ```PerCPU```

Figuring out who you are using ```SMP::me()```

## Other uses of Semaphores
### Networking
* Consider multiple threads running on server, producing data
    * Called **Producers**
* Consumers, or workers
    * pick up what the produceres output and do work on given data
        * Called the Producer/Consumer problem
* Any data structure that does not forget, like a Queue, sits between them
    * Keep it atomic
* Put backpressure on Producers (flow control)
    * When consumers cannot handle work they tell Producers to ```Stop It```
    * Have to be able to tell Producers to wait if the finite-queue is full

### Bounded-buffer
Can handle the Q and telling the sender a status
```c++
template<typename T, int N> //N is # of elements in buffer
class BB{
    T data[N];
    void put(T e){ ... }
    T get(){ ... }
}
```
* Both ```put()``` and ```get()``` are able to block
    * In the scenario that the buffer is full on ```put()```, or if the buffer is empty on ```get()```
    * Must have two flags instead of semaphore to say whether semaphore is empty/full
```c++
class B <N>{
    Semaphore nEmpty = N;
    Semaphore nFull = 0;
    Semaphore lock; // just used for protection of data structure, could also be a spin

    put(T e){
        nEmpty.down(); // if nEmpty is 0, then you block
        lock.down();
        // need an atomic Q
        // .
        // . compete over it
        // .
        lock.up();
        nFull.up();
    }

    T get(){
        nFull.down();
        //compete over the Q
        nEmpty.up();

    }
}
```
By competing over the semaphore, we know that the right number of threads are allowed in.
```c++
lock.down();
// need an atomic Q
// .
// . compete over it
// .
lock.up();
```
This is simply a thread safe Q

### Example of bad put and get
```c++
//put:
lock();
nEmpty.down();
//.
//.
//.
nFull.up();
unlock();

//get:
lock();
nFull.down();
//.
//.
//.
nEmpty.up();
unlock();
```
By swapping pairs of commands, we can be deadlock free

## Barrier
```c++
Barrier(int n) : n(n){}
void sync(){
    //up to n - 1 threads can sync
    //nth thread makes every other thread wake up
    n = n - 1;
    if(n.add_fetch(-1) == 0){
        wait.up();
    }else{
        wait.down();
        wait.up();
    }// add check to see if less than 0 for invariant
    
}
```
## Monitor
```c++
Monitor_bounded_buffer{
    condition queueIsNotFull;
    condition queueIsNotFull;
    //gurantees mutual exclusion
    void put(T v){
        [lock]
        while(queueIsFull()){
            [unlock]
            wait queueIsNotFull; // wait is a keyword
            [lock]
            // condition is pulse not a state. have to wait for the signal
            // once out of wait we know q is not full
        }
        signal queueIsNotEmpty;
    }
    T get(){
        if(queueIsEmpty()){
            wait queueIsNotEmpty;

        }
        <<is not empty>>
        // do stuff to get from queue
        <<isNotFull>>
        // q cannot be full since something is removed
        signal queueIsNotFull;
        // hand off lock
        // what if I want to continue doing work here
    }
}
bounded_buffer{
    synchronized void put(){}
    synchronized void get(){}
}
```
* Have to say synchronized
* Would be a good alternative that upon wake up you hand off the lock
* When signaled, the lock is given away to other monitor so no one can sneak in and change the state
* When singaling, we expect the other monitor to check the state of the Queue
### Problems
* If want to work after I signal
    * just make it illegal to work after the signal
* actually very difficult to atomically unlock and then wait
    * if not atomic there will be race conditions

###Fundamental Problem
* Nested Monitor Problem

## P6
For every data structure we have to ask ourselves:
* is it global
* per per thread
* per CPU
Try to make everything per thread.
1. Examine every data structure in P4 and check what scope it can have
* active thread ptr, should be per core
    * use PerCpu to get 
2. Figure out locking mechanism
3. Find shortest time needed to hold the lock, otherwise race conditions will arise
```c++
if(readyQ.isEmpty()){
    // stuff
}
```
Need lock to preserve invariants. Want to presrve the fact that the Q is empty while dealing with the Q (that is supposed to be empty)
### Semaphore details
```c++
//down:
spin.lock(); // lock should be of the same scope as the data structure
if(count == 0){
    waitingForMe.add(Thread::current());
    // cannot unlock here because thread could be picked up before contextSwitch happens
    // set state that youre in the state of blocking
    yieldButDontReady(); // without unlock its a deadlock
}
//up:
spin.lock();
```
Ask next thread on readyQ to unlock for you
* Use the callback class

###Deadlocks
Dining philosophers problem
Reason for deadlocks
1. Mutual exclusion
    * avoid this to never have deadlocks
* Things don't exclude each other from getting work done
2. Hold and wait
    * Someone holds a resource and prevents others from using it
    * never grab more than one thing at a time. Set one lock at a time
    build hierarchical locks
3. Non-preemption
    * notion of transactions so that there is some history of some transaction
    * 2 phase locking
        * get all locks up front.
        * You tell me all the locks you want, in any order you like. Go through phase where we get all your resources. While doing this, if system detecs a deadlock, it can take away resources to give to someone else. Then later these resources can be given back.
4. Cycles
    * cyclical waiting
    * change natural order and remove one

If we construct of resource graph, and we have a cycle, we immediately have a deadlock.

Have to start implementing tech for recovert